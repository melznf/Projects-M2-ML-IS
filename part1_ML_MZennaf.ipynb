{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mélissa Zennaf - Janvier 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les notebooks suivants ainsi que la librairie qui leur est associée constituent le fruit du Projet Machine Learning correspondant à l'enseignement du même nom au sein du Master Mécen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette étude sera, dans un premier temps, de mettre en place une problématique , et de modéliser cette problématique. Dans un second temps, on s'intéressera aux données disponibles sur internet pour répondre à celle-ci et on effectuera du web scraping afin de les récupérer de manière automatisée. La phase suivante sera une phase de preprocessing et de nettoyage des données afin de les rendre exploitables par des algorithmes de machine learning. Pour finir, on définira certains modèles pertinents pour répondre au mieux à la problématique et on les mettra en oeuvre. On essayera de distinguer le meilleur modèle parmis ceux testés et de présenter ses résultats afin de répondre à la problématique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problématique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tant que future jeune diplômée, je serai prochainement amenée à trouver du travail et ce sera certainement dans un autre départemet que l'Indre-et-Loire. Ma problématique est de savoir dans quel département français je suis susceptible de percevoir la rémunération la plus élevée. Existe-t-il des disparités de salaire entre les départements français ? Quels sont les déterminents et aboutissants de ces disparités ? Dans quel département s'installer pour maximiser sa rémunération ?\n",
    "\n",
    "Pour tenter de répondre à cette problématique, je vais m'appuyer sur des données économiques, géographiques, démographiques et financières concernant les départements français. \n",
    "\n",
    "A première vue, le salaire (ou plus précisément le salaire moyen) est déterminé par de multiples conditions. Les plus évidentes sont tout d'abord le niveau de vie et le dynamisme économique du département en question. On peut également citer des déterminents démographiques comme la population, ou des déterminents financiers comme le taux d'imposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le revenu moyen est une variable quantitative et continue, on s'attend à mobiliser des techniques de régression. Au niveau mathématique, on peut donc définir cela comme la recherche des $X$ pour lesquels une relation $y=f(X)$ est possible et pertinente avec $y$ la variable à expliquer, à savoir le revenu moyen au sein d'un département. On s'attachera à définir la relation $f()$ dans la partie trois de cette étude.\n",
    "\n",
    "Pour la réalisation technique de ce projet, on utilisera le langage python. La plupart des fonctions seront stockées dans un script annexe. Les librairies utiles seront numpy, requests, bs4, pandas, string, seaborn, et scikitLearn.\n",
    "\n",
    "Nous commençons par une phase de recherche internet et de récupération des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans cette première partie, nous allons scraper des données sur le web afin des se constituer une base de données.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer les librairies et fonctions nécessaires à ce travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import adresse, get_pages, find_jdn, find_wiki, find_wiki_2, gestion_ligne5, gestion_ligne9, gestion_ligne12, gestion_ligne14, gestion_ligne6, gestion_ligne7, gestion_ligne8, construit_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cours de la phase de modélisation, nous avons donc établi que nous cherchons à extraire des données sur les départements français. Pour ceci, on s'est constitué un catalogue des sources internet. Les liens menant à ces pages sont les suivants :\n",
    "\n",
    "* [pib des départements français - Wikipédia](https://fr.wikipedia.org/wiki/Liste_des_d%C3%A9partements_fran%C3%A7ais_class%C3%A9s_par_produit_int%C3%A9rieur_brut_par_habitant)\n",
    "\n",
    "* [population et superficie des départements français - Wikipédia](https://fr.wikipedia.org/wiki/Liste_des_d%C3%A9partements_fran%C3%A7ais_class%C3%A9s_par_population_et_superficie)\n",
    "\n",
    "* [nombre de communes par département - Wikipédia](https://fr.wikipedia.org/wiki/Nombre_de_communes_par_d%C3%A9partement_en_France_au_1er_janvier_2014)\n",
    "\n",
    "* [salaire par département - Journal du net](http://www.journaldunet.com/business/salaire/classement/departements/salaires)\n",
    "\n",
    "* [revenu déclaré par département - Journal du net](http://www.journaldunet.com/economie/impots/classement/departements/revenu-fiscal)\n",
    "\n",
    "* [taxe foncière par département - Journal du net](http://www.journaldunet.com/economie/impots/classement/departements/taxe-fonciere-bati)\n",
    "\n",
    "* [impôt sur le revenu par département - Journal du net](http://www.journaldunet.com/economie/impots/classement/departements/impot-revenu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe est de récupérer les données issues de ces sites internet via des fonction indépendantes qui récupérent les colonnes de chaque tableau pour chaque ligne du tableau. On obtient finalement une liste de liste où une liste correspond aux données pour une variable. Pour chaque source, nous avons donc une liste de liste. \n",
    "\n",
    "On utilise requests, en particulier la commande ``get`` puis on utilise BeatifulSoup ainsi que le parceur \"lxml\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque source, nous faisons appel à la fonction construite par nos soins. On stock le résultat sous la forme d'une liste de liste. Par exemple, pour la première source, la fonction est construite de la sorte :\n",
    "\n",
    "``def adresse(ad):\n",
    "    page_brute=get(ad)\n",
    "    texte = page_brute.text\n",
    "    texte = texte.replace(\"\\n\", \" \")\n",
    "    texte = texte.replace(\"\\t\", \" \")\n",
    "    motif = re.compile(\"<tr>\\s*<td><a(.*?)</tr>\")\n",
    "    soupe = BS(texte, \"lxml\")\n",
    "    return soupe``\n",
    "   \n",
    "Cette fonction fait appel à la library requests et nous permet d'obtenir le code html des pages. Une fois le texte obtenu, on applique une deuxième fonction adaptée à la source (Wikipédia ou Journal du net) qui nous permet de trouver les balises correspondantes à une ligne du tableau dont on veut récupérer les données. Par exemple, pour une source Journal du net, on cherche les balises html tr qui correspondent à une ligne. \n",
    "\n",
    "``def find_jdn(soupe):\n",
    "    balise_table=soupe.find_all(name=\"table\", attrs={\"class\" : [\"odTable\"]})\n",
    "    table=balise_table[0]\n",
    "    corps=table.find_next(name=\"tbody\")\n",
    "    lignes=corps.find_all(name=\"tr\")\n",
    "    ligne1,*_ = lignes\n",
    "    return lignes``\n",
    "    \n",
    "On obtient donc le texte du corps du tableau. Une fois cela obtenu, on cherche à récupérer les données de chaque ligne grâce à la fonction suivante :\n",
    "\n",
    "``def gestion_ligne5(lignes):\n",
    "    for i in range(len(lignes)):\n",
    "        colonnes = lignes[i].find_all(name=\"td\")\n",
    "        rang, nom, salaire = colonnes\n",
    "        s=nom.text.replace('(','').replace(')', '')\n",
    "        remove_digits = str.maketrans('', '', digits)\n",
    "        res = s.translate(remove_digits)\n",
    "        liste_ligne_nom.append(\n",
    "        res.replace(' ', '').replace('', ' '))\n",
    "        liste_ligne_code1.append(int(re.findall('\\d+', nom.text)[0]))\n",
    "        liste_ligne_rmoyen.append(\n",
    "        salaire.text.rstrip().replace(\"\\xa0\", \"\").replace(\" \", \"\").replace(\"€nets/mois\", \"\"))\n",
    "    return[liste_ligne_nom, liste_ligne_rmoyen, liste_ligne_code1]``\n",
    "    \n",
    "Comme expliqué, nous récupérons une liste par variable dans le tableau de données. \n",
    "\n",
    "Toutes ces fonctions sont appliquées de manière successive. On commence toujours par une ligne de code telle que celle-ci : \n",
    "\n",
    "``lignes3=list(find_wiki(adresse(\"lien url\")))``\n",
    "\n",
    "Pour la bonne exécution du programme, l'output doit être une liste. Puis, on applique notre dernière fonction :\n",
    "\n",
    "``res3=gestion_ligne6(lignes3)``\n",
    "\n",
    "Dans le cas le plus simple, toutes les données sont sur la même page, dans ce cas, on met en entrée le lien url et on récupère directement les données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes3=list(find_wiki(adresse(\"https://fr.wikipedia.org/wiki/Liste_des_d%C3%A9partements_fran%C3%A7ais_class%C3%A9s_par_produit_int%C3%A9rieur_brut_par_habitant\")))\n",
    "res3=gestion_ligne6(lignes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes4=list(find_wiki_2(adresse(\"https://fr.wikipedia.org/wiki/Liste_des_d%C3%A9partements_fran%C3%A7ais_class%C3%A9s_par_population_et_superficie\")))\n",
    "del lignes4[3]\n",
    "res4=gestion_ligne7(lignes4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes5=list(find_wiki_2(adresse(\"https://fr.wikipedia.org/wiki/Nombre_de_communes_par_d%C3%A9partement_en_France_au_1er_janvier_2014\")))\n",
    "res5=gestion_ligne8(lignes5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas un peu différent, les données d'un tableau apparaissent sur deux pages ayant un url différent. Le premier se termine par \"/salaire\" et celui de la deuxième page se termine par \"/salaire?page=2\". Il est assez compliqué de créer une boucle dans ce cas donc on choisit d'appeler la fonction à deux reprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes=list(find_jdn(adresse(\"http://www.journaldunet.com/business/salaire/classement/departements/salaires\")))\n",
    "lignes2=list(find_jdn(adresse(\"http://www.journaldunet.com/business/salaire/classement/departements/salaires?page=2\")))\n",
    "gestion_ligne5(lignes)\n",
    "res2=gestion_ligne5(lignes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes4=list(find_jdn(adresse(\"http://www.journaldunet.com/economie/impots/classement/departements/revenu-fiscal\")))\n",
    "lignes42=list(find_jdn(adresse(\"http://www.journaldunet.com/economie/impots/classement/departements/revenu-fiscal?page=2\")))\n",
    "gestion_ligne9(lignes4)\n",
    "res1=gestion_ligne9(lignes42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes10=list(find_jdn(adresse(\"http://www.journaldunet.com/economie/impots/classement/departements/taxe-fonciere-bati\")))\n",
    "lignes102=list(find_jdn(adresse(\"http://www.journaldunet.com/economie/impots/classement/departements/taxe-fonciere-bati?page=2\")))\n",
    "gestion_ligne14(lignes10)\n",
    "res6=gestion_ligne14(lignes102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, dans ce dernier cas, il y a trois pages dont les liens se terminent de la même manière que précedemment mais avec \"/salaire?page=3\" en plus. On va cette fois créer une boucle qui nous permet de créer des liens pour les pages 2 et 3. Cette fonction est codée de la manière suivante :\n",
    "\n",
    "``def get_pages(token, nb):\n",
    "    pages = []\n",
    "    for i in range(2,nb+1):\n",
    "        j = token + str(i)\n",
    "        pages.append(j)\n",
    "    return pages``\n",
    "    \n",
    "Evidemment pour seulement 2 pages, on aurait pu les créer manuellement mais cette fonction peut être généralisée à un plus grand nombre de page, d'où son intérêt. Dans cette fonction, token est le lien et nb le nombre de déclinaison que l'on souhaite. Comme il n'existe pas de pages avec \"/salaire?page=1\", la liste va de 2 à 3.\n",
    "\n",
    "Une fois les url créés, on applique une boucle qui scrape les données pour ces deux liens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes8=list(find_jdn(adresse(\"http://www.journaldunet.com/economie/impots/classement/departements/impot-revenu\")))\n",
    "gestion_ligne12(lignes8)\n",
    "token = 'http://www.journaldunet.com/economie/impots/classement/departements/impot-revenu?page='\n",
    "pages = get_pages(token,3)\n",
    "for i in range(len(pages)) :\n",
    "    lignes82=list(find_jdn(adresse(pages[i])))\n",
    "    res8=gestion_ligne12(lignes82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constitution de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc en notre possession les listes de liste contenant nos données. On va à présent les transformer en matrice dans le but de les enregistrer en tant que data frame. On commence par créer les indices de colonne pour chaque data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme les outputs de notre scraping en matrices puis en data frame en faisant appel à la librairie pandas. On utilise ensuite plusieurs fois la fonction ``pandas.merge()`` afin de réunir nos data frame en un seul. On précise la colonne qui permet la réunion, elle peut être la colonne correspondant au nom ou au code du département selon les cas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=construit_df(res1, res2, res3, res4, res5, res6, res8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons le data frame suivant. On peut voir que l'on a plus que 91 lignes sur les 102 départements français. Cela est dû au fait que lors de la réunification de nos data frame, certaines données dont le critère de réunion n'était pas présent dans le data frame précédent ont été abandonnées. Cela explique que nous perdions des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_x</th>\n",
       "      <th>nom</th>\n",
       "      <th>pop_2012</th>\n",
       "      <th>pop_2014</th>\n",
       "      <th>pop_2016</th>\n",
       "      <th>pop_2017</th>\n",
       "      <th>pop_2018</th>\n",
       "      <th>superficie</th>\n",
       "      <th>densite</th>\n",
       "      <th>nb_commune</th>\n",
       "      <th>...</th>\n",
       "      <th>hab_m</th>\n",
       "      <th>pib_2015</th>\n",
       "      <th>pib_2005</th>\n",
       "      <th>pib_2000</th>\n",
       "      <th>décla</th>\n",
       "      <th>code_y</th>\n",
       "      <th>rmoyen</th>\n",
       "      <th>code</th>\n",
       "      <th>taxe_om</th>\n",
       "      <th>impot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>N o r d</td>\n",
       "      <td>2587128</td>\n",
       "      <td>2603472</td>\n",
       "      <td>2603723</td>\n",
       "      <td>2604361</td>\n",
       "      <td>2604361</td>\n",
       "      <td>5742,8</td>\n",
       "      <td>453,8</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>3968</td>\n",
       "      <td></td>\n",
       "      <td>23567</td>\n",
       "      <td>19794</td>\n",
       "      <td>2427</td>\n",
       "      <td>59</td>\n",
       "      <td>24887</td>\n",
       "      <td>59</td>\n",
       "      <td>18,07</td>\n",
       "      <td>3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>P a r i s</td>\n",
       "      <td>2240621</td>\n",
       "      <td>2220445</td>\n",
       "      <td>2190327</td>\n",
       "      <td>2187526</td>\n",
       "      <td>2187526</td>\n",
       "      <td>105,4</td>\n",
       "      <td>20720,0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2249975</td>\n",
       "      <td>96400</td>\n",
       "      <td>75439</td>\n",
       "      <td>67502</td>\n",
       "      <td>4007</td>\n",
       "      <td>75</td>\n",
       "      <td>48301</td>\n",
       "      <td>75</td>\n",
       "      <td>13,50</td>\n",
       "      <td>11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>B o u c h e s - d u - R h ô n e</td>\n",
       "      <td>1984784</td>\n",
       "      <td>2006069</td>\n",
       "      <td>2019717</td>\n",
       "      <td>2024162</td>\n",
       "      <td>2024162</td>\n",
       "      <td>5087</td>\n",
       "      <td>399,9</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>16604</td>\n",
       "      <td>34200</td>\n",
       "      <td>27818</td>\n",
       "      <td>23521</td>\n",
       "      <td>2570</td>\n",
       "      <td>13</td>\n",
       "      <td>26751</td>\n",
       "      <td>13</td>\n",
       "      <td>21,06</td>\n",
       "      <td>3996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>S e i n e - S a i n t - D e n i s</td>\n",
       "      <td>1538726</td>\n",
       "      <td>1571028</td>\n",
       "      <td>1606660</td>\n",
       "      <td>1623111</td>\n",
       "      <td>1623111</td>\n",
       "      <td>236,2</td>\n",
       "      <td>6918,1</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>38248</td>\n",
       "      <td>38900</td>\n",
       "      <td>27420</td>\n",
       "      <td>23305</td>\n",
       "      <td>2398</td>\n",
       "      <td>93</td>\n",
       "      <td>21768</td>\n",
       "      <td>93</td>\n",
       "      <td>21,91</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>H a u t s - d e - S e i n e</td>\n",
       "      <td>1586434</td>\n",
       "      <td>1597770</td>\n",
       "      <td>1603268</td>\n",
       "      <td>1609306</td>\n",
       "      <td>1609306</td>\n",
       "      <td>175,6</td>\n",
       "      <td>9199,6</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>43934</td>\n",
       "      <td>97500</td>\n",
       "      <td>73277</td>\n",
       "      <td>62244</td>\n",
       "      <td>3885</td>\n",
       "      <td>92</td>\n",
       "      <td>45966</td>\n",
       "      <td>92</td>\n",
       "      <td>16,04</td>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_x                                  nom pop_2012 pop_2014 pop_2016  \\\n",
       "0     59                             N o r d   2587128  2603472  2603723   \n",
       "1     75                           P a r i s   2240621  2220445  2190327   \n",
       "2     13     B o u c h e s - d u - R h ô n e   1984784  2006069  2019717   \n",
       "3     93   S e i n e - S a i n t - D e n i s   1538726  1571028  1606660   \n",
       "4     92         H a u t s - d e - S e i n e   1586434  1597770  1603268   \n",
       "\n",
       "  pop_2017 pop_2018 superficie  densite nb_commune  ...    hab_m pib_2015  \\\n",
       "0  2604361  2604361     5742,8    453,8        650  ...     3968            \n",
       "1  2187526  2187526      105,4  20720,0          1  ...  2249975    96400   \n",
       "2  2024162  2024162       5087    399,9        119  ...    16604    34200   \n",
       "3  1623111  1623111      236,2   6918,1         40  ...    38248    38900   \n",
       "4  1609306  1609306      175,6   9199,6         36  ...    43934    97500   \n",
       "\n",
       "  pib_2005 pib_2000 décla code_y rmoyen code taxe_om  impot  \n",
       "0    23567    19794  2427     59  24887   59   18,07   3414  \n",
       "1    75439    67502  4007     75  48301   75   13,50  11750  \n",
       "2    27818    23521  2570     13  26751   13   21,06   3996  \n",
       "3    27420    23305  2398     93  21768   93   21,91   3095  \n",
       "4    73277    62244  3885     92  45966   92   16,04   9162  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre finalement ce data frame au dormat csv en prévision de la suite de nos analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'df.csv'\n",
    "df.to_csv(filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cours de cette première phase du projet, on a commencé par poser la problématique et élaborer un catalogue de sources disponibles pour récupérer des données. On a ensuite procédé au scraping de celles-ci et à leur transformation en un seul jeu de données exploitable. Nous allons poursuivre sur la phase de nettoyage et de préparation des données. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
